import collections
import random
import math

def sample_contexts(filename, n_ctxs, random_seed, output_directory):
	"""
	The function `sample_contexts` reads data from a file, calculates frequencies, samples contexts
	based on specified criteria, and writes the sampled data to an output file.

	Args:
	  filename: The `filename` parameter in the `sample_contexts` function is the path to the input file
	containing the data from which contexts will be sampled.
	  n_ctxs: The `n_ctxs` parameter in the `sample_contexts` function represents the number of contexts
	you want to sample for each noun based on the frequencies calculated. It is used to determine the
	percentage of contexts to sample for each noun for each source from the total number of contexts
	available for that noun across different sources
	  random_seed: The `random_seed` parameter is used to initialize the random number generator with a
	specific seed value. This ensures that the random sampling done in the function is reproducible,
	meaning that if you run the function with the same `random_seed` value multiple times, you will get
	the same random samples each
	  output_directory: The `output_directory` parameter is a directory where the output files will be
	saved. It should be a path to the directory where you want to store the output files generated by
	the `sample_contexts` function.
	"""

	random.seed(random_seed)

	counts = collections.defaultdict(
		lambda: collections.defaultdict(int)
		)

	sources = set()
	with open(filename, encoding="utf-8") as fin:
		for line in fin:
			linesplit = line.strip().split("\t")
			source, par1, noun, *_ = linesplit
			sources.add(source)
			counts[noun][source] += 1

	to_sample = collections.defaultdict(lambda: collections.defaultdict(list))
	with open(output_directory.joinpath(f"{par1}.counts.tsv"), "w", encoding="utf-8") as fout:
		sources = list(sources)
		sources_str = '\t'.join(sources)
		print(f"NOUN\t{sources_str}", file=fout)
		for noun in counts:
			freqs = [counts[noun][source] for source in sources]
			tot = sum(freqs)
			percentages = [math.ceil(x*n_ctxs/tot) for x in freqs]

			pairs = zip(freqs, percentages)

			for i, pair in enumerate(pairs):
				source = sources[i]
				f, p = pair
				to_sample[noun][source] = sorted(random.sample(range(f), min(f, p)))

			freqs = [str(x) for x in freqs]
			freqs_str = '\t'.join(freqs)
			print(f"{noun}\t{freqs_str}", file=fout)

	indexes = collections.defaultdict(lambda: collections.defaultdict(int))
	with open(filename, encoding="utf-8") as fin, \
		open(output_directory.joinpath(f"{par1}.sampled.tsv") , "w", encoding="utf-8") as fout:
		for line in fin:
			linesplit = line.strip().split("\t")
			source, _, noun, *_ = linesplit

			example_id = indexes[noun][source]
			indexes[noun][source] += 1

			if len(to_sample[noun][source]) > 0:
				if to_sample[noun][source][0] == example_id:
					print(line.strip(), file=fout)
					to_sample[noun][source].pop(0)


if __name__ == "__main__":
	from pathlib import Path
	sample_contexts("data/output_compoundcontexts/ex.contexts.tsv", 5, 13, Path("data/output_compoundcontexts/"))
#TODO: sample contexts and add annotations